[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Course Description",
    "section": "",
    "text": "Susan Vanderplas\nAssistant Professor, University of Nebraska Lincoln\nHeike Hofmann\nProfessor, Iowa State University\nEmily Robinson\nAssistant Professor, California Polytechnic University"
  },
  {
    "objectID": "about.html#instructors",
    "href": "about.html#instructors",
    "title": "Course Description",
    "section": "",
    "text": "Susan Vanderplas\nAssistant Professor, University of Nebraska Lincoln\nHeike Hofmann\nProfessor, Iowa State University\nEmily Robinson\nAssistant Professor, California Polytechnic University"
  },
  {
    "objectID": "about.html#target-audience",
    "href": "about.html#target-audience",
    "title": "Course Description",
    "section": "Target Audience",
    "text": "Target Audience\nThis course is intended for practicing statisticians in industry, government, or academia who are responsible for communicating results of statistical analyses and data to non-statisticians.\n\nPrerequisites\nAttendees should be able to read data in, clean it, and visualize it using the language of their choice.\nExamples will be provided using ggplot2 code in R and seaborn or matplotlib in python. Instructors can assist students with R and python code during the workshop and will attempt to help with others; we do not promise familiarity with all programming languages in common use for data science."
  },
  {
    "objectID": "about.html#description",
    "href": "about.html#description",
    "title": "Course Description",
    "section": "Description",
    "text": "Description\nThis course will focus on strategies for creating data visualizations which make it easy for collaborators to gain insight from data. We will discuss different ways graphics are used during the analysis process, but will primarily focus on graphics used to communicate with non-statisticians: managers, stakeholders, and collaborators who may need to use graphics to make decisions and/or motivate changes. This course will also touch on topics such as accessibility and alt-text that are essential to ensuring that graphics meet regulatory requirements. The course will assume some familiarity with plotting packages such as base R graphics, ggplot2, seaborn, and/or matplotlib, but is not a “how to make graphics” course. Code for different plotting libraries will be provided and modified during the course."
  },
  {
    "objectID": "content/03-accessibility.html",
    "href": "content/03-accessibility.html",
    "title": "Accessibility: More than just Alt-text",
    "section": "",
    "text": "Basic overview of types of different accessibility concerns\n\nBlind/Low Vision\nData & numerical literacy\nProcessing disorders - dyslexia, dyscalculia, ADHD\n\nApproaches to navigating disability\n\nScreen reader - try out navigating with a screen reader around this site.\n\nVisual Solutions\n\nLow vision support\nLevel 1: Basic compliance/communication\n\nAlt text\nData Tables\n\nLevel 2: Engagement\n\nKeyboard navigation of visualization content\nSonification (Sakhardande et al. 2019; Acartürk, Alaçam, and Habel 2014)\nPhysicalization (Watanabe and Mizukami 2018; Goncu, Marriott, and Hurst 2010)\n\n\n\n\n\n\n\nReferences\n\nAcartürk, Cengiz, Özge Alaçam, and Christopher Habel. 2014. “Developing a Verbal Assistance System for Line Graph Comprehension.” In Design, User Experience, and Usability. User Experience Design for Diverse Interaction Platforms and Environments, edited by Aaron Marcus, 373–82. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-07626-3_34.\n\n\nGoncu, Cagatay, Kim Marriott, and John Hurst. 2010. “Usability of Accessible Bar Charts.” In Diagrammatic Representation and Inference, edited by Ashok K. Goel, Mateja Jamnik, and N. Hari Narayanan, 167–81. Berlin, Heidelberg: Springer. https://doi.org/10.1007/978-3-642-14600-8_17.\n\n\nSakhardande, Prabodh, Anirudha Joshi, Charudatta Jadhav, and Manjiri Joshi. 2019. “Comparing User Performance on Parallel-Tone, Parallel-Speech, Serial-Tone and Serial-Speech Auditory Graphs.” In Human-Computer Interaction – INTERACT 2019, edited by David Lamas, Fernando Loizides, Lennart Nacke, Helen Petrie, Marco Winckler, and Panayiotis Zaphiris, 247–66. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-030-29381-9_16.\n\n\nWatanabe, Tetsuya, and Hikaru Mizukami. 2018. “Effectiveness of Tactile Scatter Plots: Comparison of Non-Visual Data Representations.” In Computers Helping People with Special Needs, edited by Klaus Miesenberger and Georgios Kouroupetroglou, 628–35. Cham: Springer International Publishing. https://doi.org/10.1007/978-3-319-94277-3_97."
  },
  {
    "objectID": "content/01-Fundamentals.html",
    "href": "content/01-Fundamentals.html",
    "title": "Fundamentals of Graphical Communication",
    "section": "",
    "text": "In order to design graphics for the human perceptual system, we must understand, at a basic level, the makeup of the perceptual system. There are multiple levels of perception that must correctly function in order to perceive visual stimuli successfully, but a somewhat simplistic higher-level analogy would be that we must understand both the hardware and software of the human visual system to create effective graphics.\nThe “hardware”, in this analogy, consists of the neurons that make up the eyes, optic nerve, and the brain itself. The higher-level functions (object recognition, working memory, etc.) comprise the “software” component. In addition, much like computer software, there are different programs running simultaneously; these programs may interact with each other, run sequentially, or run in parallel. Here, we provide an overview of the important components of the visual system that influence graphical perception. First, we discuss the grey-matter (hardware) components of the visual system, then we examine the higher-level cognitive heuristics (software) that order the raw input and construct our visual environment.\n\n\nThe physiology of perception is complex; what follows is a brief overview of the physiology of perception, focusing on the areas most important to the perception of statistical graphics. It is important to distinguish between the sensation (the retinal image) and the perception (the corresponding mental representation) of an object. This overview will entirely ignore the finer details of the organization of the brain: feature detector cells, specific processing units for certain types of visual stimuli, and most of the experiments and incidents that led to our current understanding of how the brain processes visual information. A more thorough presentation of these aspects of perception can be found in Goldstein and Cacciamani (2022).\n\n\nThe eye is a complex apparatus, but for our purposes, the most important component of the eye is the retina, which contains the sensory cells responsible for transforming light waves into electrical information in the form of neural signals. These sensory cells are specialized neurons, known as rods and cones, which perceive light intensity (brightness) and wavelength (color), respectively. One section of the retina, known as the fovea, contains only cones; the rest of the retina contains a mixture of rods and cones. Figure 1 depicts the structure of the eye with a closeup of the retina.\n\n\n\n\n\n\nFigure 1: The human eye, with closeup of receptor cells in the retina. Image Source License Authors: OpenStax Copyright Holders: Rice University Publishers: OpenStax OpenStax Biology\n\n\n\nAnother important region of the retina is the blindspot, the area where the optic nerve exits the eye to connect the retina to the brain. There are no rods or cones in this region of the retina, and any vision in the region of space that maps onto this point is a result of two mechanisms: binocular vision (the other eye fills in the missing information) and your brain “filling in” what it believes should be there.\n\n\n\n\n\n\nFigure 2: Absorption spectra of rods and short (blue), medium (green), and long (red) wave cones. Image modified from Pancrat’s Wikimedia Commons work. License.\n\n\n\nFigure 2 shows the responsiveness of rods and each of the three types of cones to wavelengths of light in the visual spectrum. As a result of the response of cone cells to different wavelengths of light, humans with normal color vision can better distinguish colors in the yellow-green portion of the color spectrum compared to colors in the red or blue portions of the spectrum.\n\n\n\n\n\n\nImplications for Color Schemes\n\n\n\nRainbow-style color schemes are seldom appropriate for conveying numerical values, because the correspondence between perceived information and the displayed information is not accurately maintained by the visual system (Golebiowska and Coltekin 2022; Liu and Heer 2018; Borland and Taylor 2007; Light and Bartlein 2004). Rainbow schemes may perform slightly better in situations where the goal is to emphasize distributions of values (Reda 2022), but this effect is small relative to the disadvantages of rainbow color schemes for accessibility and interpretability.\nMoreover, if a viewer has any level of color vision impairment (colloquially, ‘color blindness’), the viewer cannot perceive the full spectrum of colors. An estimated 5% of the population (10% of males, less than 1% of females) has some form of color vision impairment. Rainbow color schemes perform particularly poorly when color vision is impaired.\n\n\n\n\n\nOnce light hits the retina and causes a signal in the receptor cells, the information travels along the optic nerve and into the brain. Multiple neighboring rods are connected to the same neuron, where each cone is connected to a single neuron. The combined wiring of rod cells is responsible for the Hermann grid illusion and the Mach bands seen in Figure 3. Both of these illusions are a product of lateral inhibition, which is a result of the wiring of rod cells in the retina. Essentially, neurons can only fire at a specific rate, so when neighboring cells are all stimulated simultaneously, the combined neuron cannot fire fast enough to pass on all of the signals, causing inhibition. The specifics of this response and its relationship with the wiring of the receptor cells are too complex for this summary.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Hermann grid illusion Image Source. License.\n\n\n\n\n\n\n\n\n\n\n\n(b) Mach Bands Image Source. License.\n\n\n\n\n\n\n\n\nFigure 3: Illusions which are thought to arise due to inhibition. In the Hermann grid illusion, dark blobs appear at the intersection of the white lines. In the Mach band illusion, the region where different shaded bands meet seems to have more contrast than the middle of the bands.\n\n\n\nOnce neural impulses have left the retina through the optic nerve, they travel to the visual cortex by way of several specialized structures within the brain that process lower-level signals. Receptor cells in the visual cortex respond to specific angles, spatial locations, colors, and intensities, and arrays of these special ‘feature detector cells’ process the information into a form used by higher-level processes (Hubel and Wiesel 1962). These higher-level processes are what we have previously called ‘software’: they are not directly related to the physical brain, but they do process information heuristically to produce higher-level reasoning and conclusions. In the next section, we explore some of the higher-level processes responsible for visual perception.\n\n\n\n\nMany of the processes for visual perception run simultaneously; in absence of a strict temporal ordering, we will start with the more basic tasks of visual perception and proceed towards higher-level processes.\n\n\nIn many tasks, it is necessary to pay attention to many parallel input streams simultaneously; this is particularly true for complex tasks like driving a car. These tasks demand divided attention; the brain must process many different sources of information in parallel. By contrast, most image recognition tasks require selective attention, that is, focusing on specific objects and ignoring everything else.\nSelective attention is accomplished by focusing the fovea (the area with the highest visual acuity) on the object. For instance, if the object is a page of text, each word will pass through the fovea, producing a focused stream of visual input. This stream of input consists of saccades (jumps between points of focus) and pauses in which the visual information is relayed to the brain.\nSelective attention is generally necessary for perception to occur, though there is some information that is encoded automatically. The “gorilla” film experiment demonstrates that even when there is attention focused on a task, information extraneous to that task is not always encoded, that is, when participants focused on counting the number of passes between players in the basketball game, many did not notice the gorilla walking through the middle of the court. It is important to understand which parts of a visual stimulus are the focus of a given perceptual task, because most of the information encoded by the brain is a result of selective attention. Eye-tracking can be an important tool useful to understand these perceptual processes, but participants may also be able to self-report which parts of a stimulus contributed to their decision.\nWithin the brain, attention is important because it allows different regions of the brain which process color, shape, and position to integrate these perceptions into a multifaceted mental representation of the object (Goldstein and Cacciamani 2022). This process, known as binding, is essential to coherently encode a scene into working memory. Feature integration theory (Treisman 1980) suggests that these separate streams of information are initially encoded in the preattentive stage of object perception; focusing on the object triggers the binding of these separate streams into a single coherent stream of information. Many single features, such as color, length, and texture are preattentive, because they can be pinpointed in an image without focused attention (and thus can be located faster), but specific combinations of color and shape require attention (because the features must be bound together) and are thus more difficult to search. Preattentive features are generally processed in parallel (that is, the entire scene is processed nearly simultaneously), while features requiring attention are processed serially.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Features detected serially or in parallel. In general, features detected in parallel are processed pre-attentively, while features detected serially require focused attention.\n\n\n\nExamples of features processed serially and in parallel are shown in Figure 4 [Helander, Landauer, and Prabhu (1997); Chapter 6].\nFeature integration as a result of attention enables the brain to process a figure holistically and integrate all of the separate aspects of the object into a single perceptual experience. This processing is important for the most basic visual processes we take for granted, including object perception.\n\n\n\nThe most basic task of the visual system is to perceive objects in the world around us. This is an inherently difficult task, however, because the retina is a flat, two-dimensional surface responsible for conveying a three-dimensional visual scene. This dimensional reduction means that there are multiple three-dimensional stimuli that can produce the same visual image on the retina. This is known as the inverse projection problem - an infinite number of three-dimensional objects produce the same two-dimensional image. Less relevant to statistical graphics, but still complicating the object perception process, a single object can be viewed from a multitude of angles, in many different situations which may affect the retinal image (lighting, partial obstruction, etc). In addition, we recognize objects even when they are partially obscured or viewed from an angle we have not previously seen. These problems mean that the brain must utilize many different heuristics to increase the accuracy of the perceived world relative to an ambiguous stimulus.\nThe most commonly cited set of heuristics for object perception (and the set most relevant to statistical graphics) arise from the Gestalt school of psychology and are known as the Principles of Grouping. These principles relate to the idea ``the whole is greater than the sum of the parts’’, that is, that the components of a visual stimulus, when combined, create something that is more meaningful than the separate components considered individually. The Gestalt principles of grouping are as follows:\n\nPragnanz (the law of closure) Every stimulus pattern is seen so that the resulting structure is as simple as possible.\nProximity Things that are close in space appear to be grouped.\nSimilarity Similar items appear to be grouped together. The law of similarity is usually subordinate to the law of proximity.\nGood Continuation Points that can be connected to form straight lines or smooth curves seem to belong together, and lines seem to follow the smoothest path.\nCommon Fate Things moving in the same direction are part of a single group.\nFamiliarity Things are more likely to form groups if the groups are familiar.\nCommon Region Things that are in the same region (container) appear to be grouped together\nUniform Connectedness A connected region of objects is perceived as a single unit.\nSynchrony Events occurring at the same time will be perceived as belonging together.\n\nThese principles are demonstrated in Figure 5.\n\n\n\n\n\n\nFigure 5: Gestalt principles of grouping\n\n\n\n\n\n\nMiller (1956) suggested that active memory can contain only 7 (plus or minus two) chunks of information. A chunk of information could be a single letter or number, a meaningful collection of several letters or numbers (e.g. a word or an area code), or an association. This limitation is important in designing information for graphical consumption. For instance, the number of categories in legends should be limited to 7, to allow a viewer to store the associations within the legend and then use that information to understand the graph. Abuse of this limitation is referred to as a “color mapping attack” in Conti, Ahamad, and Stasko (2005), a paper detailing the various ways to “attack” a human visualization system. Similarly, viewers should not be expected to remember more than 7 “chunks” of information from a single graph. Due to these limitations in memory, when a single color scale is used to represent more than one order of magnitude of variation, using a logarithmic scale provides more optimal information scaling than using a linear color scale (Sun et al. 2012; Varshney and Sun 2013).\n\n\n\nIntegrating multiple dimensions of information (or mentally combining multiple graphics) is another area which can strain the ability of the brain to utilize information effectively. Well-constructed graphs can help the brain to integrate information by connecting points across dimensions (through the use of regression lines, clustering, etc.), which creates “chunks” of information that can then be stored in memory in a more compressed format. Gestalt principles of grouping are useful heuristics in part because they help define how these chunks of information form. In chart design, creating chunks of information is useful because this allows people to draw conclusions from multiple sets of data across multiple dimensions (Gattis and Holyoak 1996). Poorly created graphics may make this task harder or even promote the encoding of misleading chunks; for instance, data that is overplotted may obscure the important trend and may also produce chunks which lead to the wrong associations being stored in memory. This integration limitation is very much related to short-term memory, but is also constrained by mental effort limitations and processing capacity. As a result, it is important to reduce the effort required to integrate multiple graphics.\n\n\n\nHuman attention is limited; thus visualizations which do not focus attention on important aspects of the data are likely to confuse the reader.\n\n“The greatest value of a picture is when it forces us to notice what we never expected to see”. (Tukey 1977)\n\nWhen there are too many salient features to notice anything in particular, attention is split too many ways to gain useful information from the picture. Graphics should present data in a controlled fashion, so that focused attention is rewarded with useful information taken from the graph. Conti, Ahamad, and Stasko (2005) describes graphs that do not follow this principle as “processing attacks”, in that the overload the “CPU” with needless calculations and mental manipulations that are ultimately futile to understanding the data.\nThe consequence of the limits of human perception and processing capacity is that there is a limited amount of information one can expect to portray graphically; thus graphics should be designed to most efficiently communicate information so that this cognitive overload does not occur. The next section presents studies which examine the perception of graphs and charts directly across a wide range of perceptual levels and experimental conditions."
  },
  {
    "objectID": "content/01-Fundamentals.html#hardware",
    "href": "content/01-Fundamentals.html#hardware",
    "title": "Fundamentals of Graphical Communication",
    "section": "",
    "text": "The physiology of perception is complex; what follows is a brief overview of the physiology of perception, focusing on the areas most important to the perception of statistical graphics. It is important to distinguish between the sensation (the retinal image) and the perception (the corresponding mental representation) of an object. This overview will entirely ignore the finer details of the organization of the brain: feature detector cells, specific processing units for certain types of visual stimuli, and most of the experiments and incidents that led to our current understanding of how the brain processes visual information. A more thorough presentation of these aspects of perception can be found in Goldstein and Cacciamani (2022).\n\n\nThe eye is a complex apparatus, but for our purposes, the most important component of the eye is the retina, which contains the sensory cells responsible for transforming light waves into electrical information in the form of neural signals. These sensory cells are specialized neurons, known as rods and cones, which perceive light intensity (brightness) and wavelength (color), respectively. One section of the retina, known as the fovea, contains only cones; the rest of the retina contains a mixture of rods and cones. Figure 1 depicts the structure of the eye with a closeup of the retina.\n\n\n\n\n\n\nFigure 1: The human eye, with closeup of receptor cells in the retina. Image Source License Authors: OpenStax Copyright Holders: Rice University Publishers: OpenStax OpenStax Biology\n\n\n\nAnother important region of the retina is the blindspot, the area where the optic nerve exits the eye to connect the retina to the brain. There are no rods or cones in this region of the retina, and any vision in the region of space that maps onto this point is a result of two mechanisms: binocular vision (the other eye fills in the missing information) and your brain “filling in” what it believes should be there.\n\n\n\n\n\n\nFigure 2: Absorption spectra of rods and short (blue), medium (green), and long (red) wave cones. Image modified from Pancrat’s Wikimedia Commons work. License.\n\n\n\nFigure 2 shows the responsiveness of rods and each of the three types of cones to wavelengths of light in the visual spectrum. As a result of the response of cone cells to different wavelengths of light, humans with normal color vision can better distinguish colors in the yellow-green portion of the color spectrum compared to colors in the red or blue portions of the spectrum.\n\n\n\n\n\n\nImplications for Color Schemes\n\n\n\nRainbow-style color schemes are seldom appropriate for conveying numerical values, because the correspondence between perceived information and the displayed information is not accurately maintained by the visual system (Golebiowska and Coltekin 2022; Liu and Heer 2018; Borland and Taylor 2007; Light and Bartlein 2004). Rainbow schemes may perform slightly better in situations where the goal is to emphasize distributions of values (Reda 2022), but this effect is small relative to the disadvantages of rainbow color schemes for accessibility and interpretability.\nMoreover, if a viewer has any level of color vision impairment (colloquially, ‘color blindness’), the viewer cannot perceive the full spectrum of colors. An estimated 5% of the population (10% of males, less than 1% of females) has some form of color vision impairment. Rainbow color schemes perform particularly poorly when color vision is impaired.\n\n\n\n\n\nOnce light hits the retina and causes a signal in the receptor cells, the information travels along the optic nerve and into the brain. Multiple neighboring rods are connected to the same neuron, where each cone is connected to a single neuron. The combined wiring of rod cells is responsible for the Hermann grid illusion and the Mach bands seen in Figure 3. Both of these illusions are a product of lateral inhibition, which is a result of the wiring of rod cells in the retina. Essentially, neurons can only fire at a specific rate, so when neighboring cells are all stimulated simultaneously, the combined neuron cannot fire fast enough to pass on all of the signals, causing inhibition. The specifics of this response and its relationship with the wiring of the receptor cells are too complex for this summary.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Hermann grid illusion Image Source. License.\n\n\n\n\n\n\n\n\n\n\n\n(b) Mach Bands Image Source. License.\n\n\n\n\n\n\n\n\nFigure 3: Illusions which are thought to arise due to inhibition. In the Hermann grid illusion, dark blobs appear at the intersection of the white lines. In the Mach band illusion, the region where different shaded bands meet seems to have more contrast than the middle of the bands.\n\n\n\nOnce neural impulses have left the retina through the optic nerve, they travel to the visual cortex by way of several specialized structures within the brain that process lower-level signals. Receptor cells in the visual cortex respond to specific angles, spatial locations, colors, and intensities, and arrays of these special ‘feature detector cells’ process the information into a form used by higher-level processes (Hubel and Wiesel 1962). These higher-level processes are what we have previously called ‘software’: they are not directly related to the physical brain, but they do process information heuristically to produce higher-level reasoning and conclusions. In the next section, we explore some of the higher-level processes responsible for visual perception."
  },
  {
    "objectID": "content/01-Fundamentals.html#software",
    "href": "content/01-Fundamentals.html#software",
    "title": "Fundamentals of Graphical Communication",
    "section": "",
    "text": "Many of the processes for visual perception run simultaneously; in absence of a strict temporal ordering, we will start with the more basic tasks of visual perception and proceed towards higher-level processes.\n\n\nIn many tasks, it is necessary to pay attention to many parallel input streams simultaneously; this is particularly true for complex tasks like driving a car. These tasks demand divided attention; the brain must process many different sources of information in parallel. By contrast, most image recognition tasks require selective attention, that is, focusing on specific objects and ignoring everything else.\nSelective attention is accomplished by focusing the fovea (the area with the highest visual acuity) on the object. For instance, if the object is a page of text, each word will pass through the fovea, producing a focused stream of visual input. This stream of input consists of saccades (jumps between points of focus) and pauses in which the visual information is relayed to the brain.\nSelective attention is generally necessary for perception to occur, though there is some information that is encoded automatically. The “gorilla” film experiment demonstrates that even when there is attention focused on a task, information extraneous to that task is not always encoded, that is, when participants focused on counting the number of passes between players in the basketball game, many did not notice the gorilla walking through the middle of the court. It is important to understand which parts of a visual stimulus are the focus of a given perceptual task, because most of the information encoded by the brain is a result of selective attention. Eye-tracking can be an important tool useful to understand these perceptual processes, but participants may also be able to self-report which parts of a stimulus contributed to their decision.\nWithin the brain, attention is important because it allows different regions of the brain which process color, shape, and position to integrate these perceptions into a multifaceted mental representation of the object (Goldstein and Cacciamani 2022). This process, known as binding, is essential to coherently encode a scene into working memory. Feature integration theory (Treisman 1980) suggests that these separate streams of information are initially encoded in the preattentive stage of object perception; focusing on the object triggers the binding of these separate streams into a single coherent stream of information. Many single features, such as color, length, and texture are preattentive, because they can be pinpointed in an image without focused attention (and thus can be located faster), but specific combinations of color and shape require attention (because the features must be bound together) and are thus more difficult to search. Preattentive features are generally processed in parallel (that is, the entire scene is processed nearly simultaneously), while features requiring attention are processed serially.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Features detected serially or in parallel. In general, features detected in parallel are processed pre-attentively, while features detected serially require focused attention.\n\n\n\nExamples of features processed serially and in parallel are shown in Figure 4 [Helander, Landauer, and Prabhu (1997); Chapter 6].\nFeature integration as a result of attention enables the brain to process a figure holistically and integrate all of the separate aspects of the object into a single perceptual experience. This processing is important for the most basic visual processes we take for granted, including object perception.\n\n\n\nThe most basic task of the visual system is to perceive objects in the world around us. This is an inherently difficult task, however, because the retina is a flat, two-dimensional surface responsible for conveying a three-dimensional visual scene. This dimensional reduction means that there are multiple three-dimensional stimuli that can produce the same visual image on the retina. This is known as the inverse projection problem - an infinite number of three-dimensional objects produce the same two-dimensional image. Less relevant to statistical graphics, but still complicating the object perception process, a single object can be viewed from a multitude of angles, in many different situations which may affect the retinal image (lighting, partial obstruction, etc). In addition, we recognize objects even when they are partially obscured or viewed from an angle we have not previously seen. These problems mean that the brain must utilize many different heuristics to increase the accuracy of the perceived world relative to an ambiguous stimulus.\nThe most commonly cited set of heuristics for object perception (and the set most relevant to statistical graphics) arise from the Gestalt school of psychology and are known as the Principles of Grouping. These principles relate to the idea ``the whole is greater than the sum of the parts’’, that is, that the components of a visual stimulus, when combined, create something that is more meaningful than the separate components considered individually. The Gestalt principles of grouping are as follows:\n\nPragnanz (the law of closure) Every stimulus pattern is seen so that the resulting structure is as simple as possible.\nProximity Things that are close in space appear to be grouped.\nSimilarity Similar items appear to be grouped together. The law of similarity is usually subordinate to the law of proximity.\nGood Continuation Points that can be connected to form straight lines or smooth curves seem to belong together, and lines seem to follow the smoothest path.\nCommon Fate Things moving in the same direction are part of a single group.\nFamiliarity Things are more likely to form groups if the groups are familiar.\nCommon Region Things that are in the same region (container) appear to be grouped together\nUniform Connectedness A connected region of objects is perceived as a single unit.\nSynchrony Events occurring at the same time will be perceived as belonging together.\n\nThese principles are demonstrated in Figure 5.\n\n\n\n\n\n\nFigure 5: Gestalt principles of grouping\n\n\n\n\n\n\nMiller (1956) suggested that active memory can contain only 7 (plus or minus two) chunks of information. A chunk of information could be a single letter or number, a meaningful collection of several letters or numbers (e.g. a word or an area code), or an association. This limitation is important in designing information for graphical consumption. For instance, the number of categories in legends should be limited to 7, to allow a viewer to store the associations within the legend and then use that information to understand the graph. Abuse of this limitation is referred to as a “color mapping attack” in Conti, Ahamad, and Stasko (2005), a paper detailing the various ways to “attack” a human visualization system. Similarly, viewers should not be expected to remember more than 7 “chunks” of information from a single graph. Due to these limitations in memory, when a single color scale is used to represent more than one order of magnitude of variation, using a logarithmic scale provides more optimal information scaling than using a linear color scale (Sun et al. 2012; Varshney and Sun 2013).\n\n\n\nIntegrating multiple dimensions of information (or mentally combining multiple graphics) is another area which can strain the ability of the brain to utilize information effectively. Well-constructed graphs can help the brain to integrate information by connecting points across dimensions (through the use of regression lines, clustering, etc.), which creates “chunks” of information that can then be stored in memory in a more compressed format. Gestalt principles of grouping are useful heuristics in part because they help define how these chunks of information form. In chart design, creating chunks of information is useful because this allows people to draw conclusions from multiple sets of data across multiple dimensions (Gattis and Holyoak 1996). Poorly created graphics may make this task harder or even promote the encoding of misleading chunks; for instance, data that is overplotted may obscure the important trend and may also produce chunks which lead to the wrong associations being stored in memory. This integration limitation is very much related to short-term memory, but is also constrained by mental effort limitations and processing capacity. As a result, it is important to reduce the effort required to integrate multiple graphics.\n\n\n\nHuman attention is limited; thus visualizations which do not focus attention on important aspects of the data are likely to confuse the reader.\n\n“The greatest value of a picture is when it forces us to notice what we never expected to see”. (Tukey 1977)\n\nWhen there are too many salient features to notice anything in particular, attention is split too many ways to gain useful information from the picture. Graphics should present data in a controlled fashion, so that focused attention is rewarded with useful information taken from the graph. Conti, Ahamad, and Stasko (2005) describes graphs that do not follow this principle as “processing attacks”, in that the overload the “CPU” with needless calculations and mental manipulations that are ultimately futile to understanding the data.\nThe consequence of the limits of human perception and processing capacity is that there is a limited amount of information one can expect to portray graphically; thus graphics should be designed to most efficiently communicate information so that this cognitive overload does not occur. The next section presents studies which examine the perception of graphs and charts directly across a wide range of perceptual levels and experimental conditions."
  },
  {
    "objectID": "content/01-Fundamentals.html#preattentive-perception",
    "href": "content/01-Fundamentals.html#preattentive-perception",
    "title": "Fundamentals of Graphical Communication",
    "section": "Preattentive Perception",
    "text": "Preattentive Perception\nAs discussed in Figure 4, some features are processed pre-attentively, in parallel, while some features require conscious attention. When choosing features for data display, viewers will have an easier time when the feature chosen is processed in parallel than if the same data is shown using a feature that is processed serially.\nHowever, it is important not to overdo it! Combinations of preattentive features used to show different dimensions of the data are processed serially, requiring much more effort, in an effect known as interference.\n\n\n\n\n\n\n\n\n\n\n\n(a) Color\n\n\n\n\n\n\n\n\n\n\n\n(b) Shape\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Interference\n\n\n\n\n\n\n\n\n\n\n\n(d) Dual Encoding\n\n\n\n\n\n\n\nFigure 6: Shape and color are detected preattentively, but when used to encode different information, the combination is no longer preattentive. When shape and color are used to encode the same information (dual encoding), the combination is detected preattentively and is more accessible to individuals with perceptual disabilities such as colorblindness.\n\n\n\nInterference is demonstrated in Figure 6; the different point in (a) and (b) is easy to pick out, but it is much harder in (c) to separate shape and color in order to pick out differences. This is because when color and shape are used to show different features, we must consider every combination of color and shape used and individually search for points matching that description – an operation which requires a lot of time and cognitive effort. Not all combinations of color and shape are problematic, however: (d) uses color and shape to show the same variable (dual-encoding), which is useful for individuals who are color blind or may have trouble perceiving shapes. The two preattentive features support each other when used in this way, making it even easier to pick out the one mismatched point than in conditions (a), (b), or (c)."
  },
  {
    "objectID": "content/01-Fundamentals.html#conscious-perception",
    "href": "content/01-Fundamentals.html#conscious-perception",
    "title": "Fundamentals of Graphical Communication",
    "section": "Conscious Perception",
    "text": "Conscious Perception\nWhile it is useful to understand the psychology of perception and the implications of preattentive perception for understanding how much cognitive effort an operation takes, analysts are more concerned about conscious perception that occurs with attention. We care about questions like:\n\nWhich parts of the graph are the most useful for answering a question?\nHow is information from the graph combined with pre-existing knowledge?\nHow does a graph promote understanding of the underlying data?\n\nSeveral different types of models have been proposed to describe this process, but overall, “task models” and “integration models” are most consistent with available empirical evidence.\n\nTask Based Processing\nAn example of task-based processing (Ratwani, Trafton, and Boehm-Davis 2008) is shown in Figure 7.\n\n\n\n\n\n\n\n\nFigure 7: Task-based steps for evaluating the relationship between eruption length and time between eruptions for Old Faithful?\n\n\n\n\n\nQuestion: What is the relationship between the length of the eruption and the time between eruptions for Old Faithful?\n\nUnderstand the question:\n\nIdentify “length of eruption” and “time between eruptions” as things to search for in the graph.\n\nSearch for identified quantities:\n\nLook for “length of eruption” on the axes and determine that the \\(y\\)-coordinate contains that information.\nLook for “time between eruptions” on the axes and determine that the \\(x\\)-coordinate contains that information.\nVerify that these quantities are what are sought by re-reading the question.\n\nSense-making and Storytelling:\n\nEstablish that as the time between eruptions increases, the length of the eruption increases.\nNote that there seems to be a bimodal distribution of points\n\nAnswer the question:\n\nAs time between eruptions increases, length of the eruption increases.\n\n\nIn practice, the search portion of the task based framework is implicitly connected to the sense-making and storytelling portion, and viewers iterate between the two steps several times before finally proceeding to step 4. The time required for each step may change based on the reader’s familiarity with the task, the chart style, and the background knowledge required to interpret the data. Viewers who are familiar with similar graphics may be able to encode information faster and in larger chunks, answering the question more quickly (Carpenter and Shah 1998).\n\n\nInformation Integration\nCharts designed to promote chunking do so by providing viewers with cues for important features. This can help participants come to conclusions supported by the data and statistical modeling underlying the visual representation, reducing cognitive load.\nFigure 8 shows the same data using three different representations, with an additional representation illustrating the viewer’s mental model. In the first figure, (a), viewers are provided with no additional information and must group points together mentally to make sense of the data; this grouping action takes some cognitive effort, producing something like the second figure, (b). The designer could make this chunking effort less resource-intensive by\n\n\n\n\n\n\n\n\n\n\n\n(a) Data with no additional aesthetics\n\n\n\n\n\n\n\n\n\n\n\n(b) Perceived chunks in mental representation\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Data, color used to provide chunking information\n\n\n\n\n\n\n\n\n\n\n\n(d) Data, color + shape used to provide chunking information\n\n\n\n\n\n\n\nFigure 8: When graphical features such as clustering are important, using aesthetics to promote chunking of the information can help readers make sense of the data more efficiently.\n\n\n\nAnalyzing graphs using task-based models emphasizes the importance of spatial relationships between graphical elements. The gestalt laws of proximity and similarity dictate that items which are close together or physically similar (the same shape or color) are perceived as a group; this spatial perception creates “chunks” of the graph which may be encoded as single objects and thus reduce the mental bandwidth necessary to process the image. Figure 8 shows the advantage of “chunks” in graphs: in (a) there are 120 points that could be grouped into the three clusters shown in (b), but when the clustering is provided using aesthetics, the Gestalt similarity heuristic naturally groups the points for us, without much additional labor.\nAs charts become more complex, it can be difficult to consider all of the perceptual processes which might affect perception and use of a specific visualization. In these cases, cognitive models and frameworks can be extremely useful (Padilla 2018; Padilla et al. 2018). By assessing the interactions between the visualization and the cognitive model, it may be possible to identify potential areas of difficulty that can be addressed in a revised design.\nOf graphics that present information of similar complexity, graphics that require less effort to understand and search for relevant information are preferable (William S. Cleveland 1985). More complex models of the graphical perception process suggest that data are integrated on a visual level and then on a cognitive level, to form successive clusters of information. Once these clusters are formed, additional information can be integrated by comparing and contrasting different clusters to understand the higher-level meaning in the graph (Ratwani, Trafton, and Boehm-Davis 2008). Graph types which cater to this hierarchical clustering mechanism may be more easily understood by viewers than graphs that do not provide information in a manner easily assimilated by the human brain. Facetted charts may be particularly useful for mapping multidimensional data to provide “chunks” of information in a relevant manner, pre-digested for integration into the viewer’s working conceptual understanding of the dataset. Additionally, color schemes and appropriate labeling of graph features which reduce the amount of work necessary to integrate numerical information from a legend into the visual representation of the graph facilitate graphical inference (Carpenter and Shah 1998)."
  },
  {
    "objectID": "content/01-Fundamentals.html#simple-charts",
    "href": "content/01-Fundamentals.html#simple-charts",
    "title": "Fundamentals of Graphical Communication",
    "section": "Simple Charts",
    "text": "Simple Charts\nA series of experiments by (William S. Cleveland and McGill 1984, 1985, 1987) examined basic perceptual tasks, establishing the relative accuracy of comparisons made using different graphical elements. This ranking is shown in Table 1. Other researchers (C. M. Carswell 1992) have examined a wide range of studies beyond those conducted by Cleveland & McGill and used meta-analysis to collapse this ranking into position/length/angle and area/volume, as the difference in accuracy between categories 1, 2, and 3 is small compared to categories 4 and 5.\n\n\n\nTable 1: Cleveland & McGill’s ordering of graphical tasks by accuracy. Higher ranking tasks are easier for viewers than low-ranking tasks and should be preferred in graphical design.\n\n\n\n\n\nRank\nTask\n\n\n\n\n1\nPosition (common scale)\n\n\n2\nPosition (non-aligned scale)\n\n\n3\nLength, Direction, Angle, Slope\n\n\n4\nArea\n\n\n5\nVolume, Density, Curvature\n\n\n6\nShading, Color Saturation, Color Hue\n\n\n\n\n\n\nIt is important to note that the task asked of participants and the type of chart are both important: when presented with a line graph, viewers are more likely to summarize the graph in terms of the slope of the trend line (even when the x-axis is discrete); when presented with a bar graph, viewers summarize the information using discrete comparisons (M. C. Carswell and Wickens 1987; Shah and Miyake 2005). The task and the graph format interact to influence viewer perceptions, thus, when creating graphics, statisticians should match appropriate graphical formats to meaningful conclusions about the data.\n\nColor, Shape, and Discriminability\nWhile shading, color saturation, and color hue rank poorly in the task hierarchy, this does not mean that they should be used to display information. Rather, it is important to remember that the feature hierarchy in Table 1 was assembled based on numerical estimation accuracy. Estimation accuracy is not the only purpose of a chart - in fact, in general, if estimation accuracy is the only goal, a table is a better representation. While viewers may not be able to correlate a specific color to a specific numerical value, color is capable of providing ordinal information (this point is more saturated than that point) and even order of magnitude level comparisons. As color is a pre-attentive feature processed in parallel, the use of color is a trade-off between numerical precision and cognitive resources (speed and working memory).\nIt is important to consider working memory when constructing graphical scales (particularly when utilizing a discrete scale for categorical data), but it is also important to consider feature selection and discriminability as well. Color is generally believed to be preferrable for representing strata on a scatterplot (William S. Cleveland and McGill 1984), but Lewandowsky and Spence (1989) found that if color is not available or appropriate, shapes, intensity, or discriminable letters may be utilized without a significant decrease in accuracy.\nDiscriminable letters are those which do not share physical features such as closure and symmetry, such as the letters H, Q, and X; confusable letters, such as H, E, and F, are associated with significantly less accurate perception. Demiralp, Bernstein, and Heer (2014) synthesized experimental evaluations of stimuli to create “perceptual kernels” describing the perceived distance between values; multidimensional scaling of the resulting distance matrix produces four distinct groups of shapes which share features (triangles with various degrees of rotation, squares and diamonds, and non-convex shapes such as x, +, and *). This separation suggests that feature integration underlies many of the processing speed effects found in studies examining discrete palettes and scales: palettes which are composed of confusable shapes, letters, or colors will require more processing time (and decrease accuracy) compared with discriminable palettes.\n\n\nOther Considerations\nOther graph features can also influence viewer inferences: multiple studies suggest that our mental schematic for a graph is most consistent with a \\(45^\\circ\\) trend line (William S. Cleveland, McGill, and McGill 1988; Tversky and Schiano 1989). “Banking to \\(45^\\circ\\)” is a commonly-cited recommendation for optimal graphics (it is also quite old, according to Wickham (2013)).\nAxis scale transformations can make it easier for viewers to spot outliers of data conforming to skewed distributions (though this does require some domain-specific knowledge of statistical distributions), and appropriately labeled graphs can reduce the working memory requirements by reducing the number of back-and-forth comparisons required to pass information into working memory (Shah and Miyake 2005)."
  },
  {
    "objectID": "content/01-Fundamentals.html#complex-domain-specific-charts",
    "href": "content/01-Fundamentals.html#complex-domain-specific-charts",
    "title": "Fundamentals of Graphical Communication",
    "section": "Complex, Domain-Specific Charts",
    "text": "Complex, Domain-Specific Charts"
  },
  {
    "objectID": "content/01-Fundamentals.html#center-primary-comparisons",
    "href": "content/01-Fundamentals.html#center-primary-comparisons",
    "title": "Fundamentals of Graphical Communication",
    "section": "Center Primary Comparisons",
    "text": "Center Primary Comparisons"
  },
  {
    "objectID": "content/01-Fundamentals.html#reduce-cognitive-load",
    "href": "content/01-Fundamentals.html#reduce-cognitive-load",
    "title": "Fundamentals of Graphical Communication",
    "section": "Reduce Cognitive Load",
    "text": "Reduce Cognitive Load"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Workshop: Effective Graphics for Visual Communication with Data",
    "section": "",
    "text": "This schedule is highly tentative and subject to change at this time.\n\n\n\nTime\nTitle\nDescription\n\n\n\n\n8:30 - 9:00 AM\nIntroductions and Setup\nInstructors and students introduce themselves and get computers set up.\n\n\n9:00 - 10:45 AM\nFundamentals of Graphical Communication\nThe interaction between cognitive processes and graphics: how do we ensure people can read our charts?\nSlides\n\n\n10:45 - 11:00 AM\nBreak\n\n\n\n11:00 - 12:00 PM\nExploratory Data Analysis\nStrategies for using graphics to generate insight about new data through rapid iteration.\nSlides\n\n\n12:00 - 1:00 PM\nLunch\n\n\n\n1:00 - 2:45 PM\nAccessibility: more than just alt-text\nAccessibility guidelines applied to graphics. We will discuss color contrast rules, ways to help make graphics accessible to colorblind individuals, those with vision acuity loss, and those who use screen readers.\nSlides\n\n\n2:45 - 3:00 PM\nBreak\n\n\n\n3:00 - 3:20 PM\nThe Rules… and when to break them\nWe’ve spent the day up to this point discussing tactics for creating good data visualizations, but sometimes, the rules get in the way of effective communication with a specific audience. When is it ok to break these rules?\nSlides\n\n\n3:20 - 3:30\nBreak\n\n\n\n3:30 - 5:00 PM\nWorkshop: Improving our graphics\nWorking individually or in groups, we will improve existing graphics in order to apply the ideas in this workshop. Individuals can bring their own graphics to workshop or use graphics we’ve provided."
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "Workshop: Effective Graphics for Visual Communication with Data",
    "section": "",
    "text": "This schedule is highly tentative and subject to change at this time.\n\n\n\nTime\nTitle\nDescription\n\n\n\n\n8:30 - 9:00 AM\nIntroductions and Setup\nInstructors and students introduce themselves and get computers set up.\n\n\n9:00 - 10:45 AM\nFundamentals of Graphical Communication\nThe interaction between cognitive processes and graphics: how do we ensure people can read our charts?\nSlides\n\n\n10:45 - 11:00 AM\nBreak\n\n\n\n11:00 - 12:00 PM\nExploratory Data Analysis\nStrategies for using graphics to generate insight about new data through rapid iteration.\nSlides\n\n\n12:00 - 1:00 PM\nLunch\n\n\n\n1:00 - 2:45 PM\nAccessibility: more than just alt-text\nAccessibility guidelines applied to graphics. We will discuss color contrast rules, ways to help make graphics accessible to colorblind individuals, those with vision acuity loss, and those who use screen readers.\nSlides\n\n\n2:45 - 3:00 PM\nBreak\n\n\n\n3:00 - 3:20 PM\nThe Rules… and when to break them\nWe’ve spent the day up to this point discussing tactics for creating good data visualizations, but sometimes, the rules get in the way of effective communication with a specific audience. When is it ok to break these rules?\nSlides\n\n\n3:20 - 3:30\nBreak\n\n\n\n3:30 - 5:00 PM\nWorkshop: Improving our graphics\nWorking individually or in groups, we will improve existing graphics in order to apply the ideas in this workshop. Individuals can bring their own graphics to workshop or use graphics we’ve provided."
  },
  {
    "objectID": "content/00-Setup.html",
    "href": "content/00-Setup.html",
    "title": "Setting Up for the Workshop",
    "section": "",
    "text": "This workshop is set up to be largely language-agnostic (at least with regard to programming language). We will provide examples using ggplot2 and seaborn or matplotlib in python.\nScreenshots will be provided using RStudio as an IDE for both R and Python, but you are free to use any IDE you wish for this workshop.\n\n\n\n\n\n\nSetting Up R, RStudio, and ggplot2\n\n\n\n\n\nStart here - Instructions for installing R and RStudio for Windows, Mac, and Linux\nOpen R or RStudio. Follow these instructions to install ggplot2 (or the whole tidyverse, if you prefer).\nIf you also plan to use python with RStudio, install the reticulate package after you have installed python.\n\n\n\n\n\n\n\n\n\nSetting Up Python, Seaborn, and Matplotlib\n\n\n\n\n\nStart here - Instructions for installing Python 3 for Windows, Mac, and Linux\nIf you wish, install a development environment such as VSCode or Spyder, or install R and RStudio to use RStudio as an IDE for python.\nInstall Seaborn, which will automatically install matplotlib."
  },
  {
    "objectID": "content/contents.html",
    "href": "content/contents.html",
    "title": "Workshop Materials",
    "section": "",
    "text": "Setting Up for the Workshop\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFundamentals of Graphical Communication\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAccessibility: More than just Alt-text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe Rules, and when to break them…\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWorkshop: Improving Our Graphics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  }
]