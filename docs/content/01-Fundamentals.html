<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Workshop: Effective Graphics for Visual Communication with Data - Fundamentals of Graphical Communication</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Workshop: Effective Graphics for Visual Communication with Data</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">Course Description</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-materials" role="button" data-bs-toggle="dropdown" aria-expanded="false" rel="" target="">
 <span class="menu-text">Materials</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-materials">    
        <li>
    <a class="dropdown-item" href="../content/contents.html" rel="" target="">
 <span class="dropdown-text">Workshop Materials</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../content/00-Setup.html" rel="" target="">
 <span class="dropdown-text">Setting Up for the Workshop</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../content/01-Fundamentals.html" rel="" target="">
 <span class="dropdown-text">Fundamentals of Graphical Communication</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#a-quick-introduction-to-perception-and-cognition" id="toc-a-quick-introduction-to-perception-and-cognition" class="nav-link active" data-scroll-target="#a-quick-introduction-to-perception-and-cognition">A Quick Introduction to Perception and Cognition</a>
  <ul class="collapse">
  <li><a href="#hardware" id="toc-hardware" class="nav-link" data-scroll-target="#hardware">Hardware</a>
  <ul class="collapse">
  <li><a href="#the-eye" id="toc-the-eye" class="nav-link" data-scroll-target="#the-eye">The Eye</a></li>
  <li><a href="#the-brain" id="toc-the-brain" class="nav-link" data-scroll-target="#the-brain">The Brain</a></li>
  </ul></li>
  <li><a href="#software" id="toc-software" class="nav-link" data-scroll-target="#software">Software</a>
  <ul class="collapse">
  <li><a href="#attention-and-perception" id="toc-attention-and-perception" class="nav-link" data-scroll-target="#attention-and-perception">Attention and Perception</a></li>
  <li><a href="#object-perception" id="toc-object-perception" class="nav-link" data-scroll-target="#object-perception">Object Perception</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#the-psychology-of-charts" id="toc-the-psychology-of-charts" class="nav-link" data-scroll-target="#the-psychology-of-charts">The Psychology of Charts</a>
  <ul class="collapse">
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  </ul></li>
  <li><a href="#strategies-for-readability" id="toc-strategies-for-readability" class="nav-link" data-scroll-target="#strategies-for-readability">Strategies for Readability</a>
  <ul class="collapse">
  <li><a href="#center-primary-comparisons" id="toc-center-primary-comparisons" class="nav-link" data-scroll-target="#center-primary-comparisons">Center Primary Comparisons</a></li>
  <li><a href="#reduce-cognitive-load" id="toc-reduce-cognitive-load" class="nav-link" data-scroll-target="#reduce-cognitive-load">Reduce Cognitive Load</a></li>
  </ul></li>
  <li><a href="#testing-multiple-versions-of-a-chart" id="toc-testing-multiple-versions-of-a-chart" class="nav-link" data-scroll-target="#testing-multiple-versions-of-a-chart">Testing Multiple Versions of a Chart</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Fundamentals of Graphical Communication</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="a-quick-introduction-to-perception-and-cognition" class="level1">
<h1>A Quick Introduction to Perception and Cognition</h1>
<p>In order to design graphics for the human perceptual system, we must understand, at a basic level, the makeup of the perceptual system. There are multiple levels of perception that must correctly function in order to perceive visual stimuli successfully, but a somewhat simplistic higher-level analogy would be that we must understand both the hardware and software of the human visual system to create effective graphics.</p>
<p>The “hardware”, in this analogy, consists of the neurons that make up the eyes, optic nerve, and the brain itself. The higher-level functions (object recognition, working memory, etc.) comprise the “software” component. In addition, much like computer software, there are different programs running simultaneously; these programs may interact with each other, run sequentially, or run in parallel. Here, we provide an overview of the important components of the visual system that influence graphical perception. First, we discuss the grey-matter (hardware) components of the visual system, then we examine the higher-level cognitive heuristics (software) that order the raw input and construct our visual environment.</p>
<section id="hardware" class="level2">
<h2 class="anchored" data-anchor-id="hardware">Hardware</h2>
<p>The physiology of perception is complex; what follows is a brief overview of the physiology of perception, focusing on the areas most important to the perception of statistical graphics. It is important to distinguish between the sensation (the retinal image) and the perception (the corresponding mental representation) of an object. This overview will entirely ignore the finer details of the organization of the brain: feature detector cells, specific processing units for certain types of visual stimuli, and most of the experiments and incidents that led to our current understanding of how the brain processes visual information. A more thorough presentation of these aspects of perception can be found in <span class="citation" data-cites="goldsteinSensationPerception2022">Goldstein and Cacciamani (<a href="#ref-goldsteinSensationPerception2022" role="doc-biblioref">2022</a>)</span>.</p>
<section id="the-eye" class="level3">
<h3 class="anchored" data-anchor-id="the-eye">The Eye</h3>
<p>The eye is a complex apparatus, but for our purposes, the most important component of the eye is the retina, which contains the sensory cells responsible for transforming light waves into electrical information in the form of neural signals. These sensory cells are specialized neurons, known as rods and cones, which perceive light intensity (brightness) and wavelength (color), respectively. One section of the retina, known as the fovea, contains only cones; the rest of the retina contains a mixture of rods and cones. <a href="#fig-retina-diagram">Figure&nbsp;1</a> depicts the structure of the eye with a closeup of the retina.</p>
<div id="fig-retina-diagram" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/9/9e/Figure_36_05_02.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;1: The human eye, with closeup of receptor cells in the retina.<span class="fig-citation"><a href="https://commons.wikimedia.org/wiki/File:Figure_36_05_02.png">Image Source</a> <a href="https://creativecommons.org/licenses/by/4.0/deed.en">License</a> Authors: OpenStax Copyright Holders: Rice University Publishers: OpenStax OpenStax Biology</span></figcaption>
</figure>
</div>
<p>Another important region of the retina is the blindspot, the area where the optic nerve exits the eye to connect the retina to the brain. There are no rods or cones in this region of the retina, and any vision in the region of space that maps onto this point is a result of two mechanisms: binocular vision (the other eye fills in the missing information) and your brain “filling in” what it believes should be there.</p>
<div id="fig-color-range" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="../fig/Absorption-Spectra-Retina.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Absorption spectra of rods and short (blue), medium (green), and long (red) wave cones. <span class="fig-citation">Image modified from <a href="https://commons.wikimedia.org/wiki/File:Spectre_absorption_des_cones.svg">Pancrat’s Wikimedia Commons work</a>. <a href="https://creativecommons.org/licenses/by-sa/3.0/deed.en">License</a>.</span></figcaption>
</figure>
</div>
<p><a href="#fig-color-range">Figure&nbsp;2</a> shows the responsiveness of rods and each of the three types of cones to wavelengths of light in the visual spectrum. As a result of the response of cone cells to different wavelengths of light, humans with normal color vision can better distinguish colors in the yellow-green portion of the color spectrum compared to colors in the red or blue portions of the spectrum.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Implications for Color Schemes
</div>
</div>
<div class="callout-body-container callout-body">
<p>Rainbow-style color schemes are seldom appropriate for conveying numerical values, because the correspondence between perceived information and the displayed information is not accurately maintained by the visual system <span class="citation" data-cites="golebiowska2022a liuSomewhereRainbowEmpirical2018a borlandRainbowColorMap2007 lightEndRainbowColor2004">(<a href="#ref-golebiowska2022a" role="doc-biblioref">Golebiowska and Coltekin 2022</a>; <a href="#ref-liuSomewhereRainbowEmpirical2018a" role="doc-biblioref">Liu and Heer 2018</a>; <a href="#ref-borlandRainbowColorMap2007" role="doc-biblioref">Borland and Taylor 2007</a>; <a href="#ref-lightEndRainbowColor2004" role="doc-biblioref">Light and Bartlein 2004</a>)</span>. Rainbow schemes may perform slightly better in situations where the goal is to emphasize distributions of values <span class="citation" data-cites="redaRainbowColormapsWhat2022">(<a href="#ref-redaRainbowColormapsWhat2022" role="doc-biblioref">Reda 2022</a>)</span>, but this effect is small relative to the disadvantages of rainbow color schemes for accessibility and interpretability.</p>
<p>Moreover, if a viewer has any level of color vision impairment (colloquially, ‘color blindness’), the viewer cannot perceive the full spectrum of colors. An estimated 5% of the population (10% of males, less than 1% of females) has some form of color vision impairment. Rainbow color schemes perform particularly poorly when color vision is impaired.</p>
</div>
</div>
</section>
<section id="the-brain" class="level3">
<h3 class="anchored" data-anchor-id="the-brain">The Brain</h3>
<p>Once light hits the retina and causes a signal in the receptor cells, the information travels along the optic nerve and into the brain. Multiple neighboring rods are connected to the same neuron, where each cone is connected to a single neuron. The combined wiring of rod cells is responsible for the <a href="https://en.wikipedia.org/wiki/Grid_illusion#Theories">Hermann grid illusion</a> and the <a href="https://en.wikipedia.org/wiki/Mach_bands">Mach bands</a> seen in <a href="#fig-inhibition-illusions">Figure&nbsp;3</a>. Both of these illusions are a product of lateral inhibition, which is a result of the wiring of rod cells in the retina. Essentially, neurons can only fire at a specific rate, so when neighboring cells are all stimulated simultaneously, the combined neuron cannot fire fast enough to pass on all of the signals, causing <em>inhibition</em>. The <a href="https://en.wikipedia.org/wiki/Grid_illusion#Theories">specifics of this response</a> and its relationship with the wiring of the receptor cells are too complex for this summary.</p>
<div id="fig-inhibition-illusions" class="quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://upload.wikimedia.org/wikipedia/commons/b/be/HermannGrid.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Hermann grid illusion <span class="fig-citation"><a href="https://en.wikipedia.org/wiki/File:HermannGrid.svg">Image Source</a>. <a href="https://creativecommons.org/publicdomain/zero/1.0/deed.en">License</a>.</span></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../fig/Mach-Bands.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Mach Bands <span class="fig-citation"><a href="https://commons.wikimedia.org/wiki/File:Bandes_de_mach.PNG">Image Source</a>. <a href="https://en.wikipedia.org/wiki/en:Free_Art_License">License</a>.</span></figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;3: Illusions which are thought to arise due to inhibition. In the Hermann grid illusion, dark blobs appear at the intersection of the white lines. In the Mach band illusion, the region where different shaded bands meet seems to have more contrast than the middle of the bands.</figcaption><p></p>
</figure>
</div>
<p>Once neural impulses have left the retina through the optic nerve, they travel to the visual cortex by way of several specialized structures within the brain that process lower-level signals. Receptor cells in the visual cortex respond to specific angles, spatial locations, colors, and intensities, and arrays of these special ‘feature detector cells’ process the information into a form used by higher-level processes <span class="citation" data-cites="hubelReceptiveFieldsBinocular1962">(<a href="#ref-hubelReceptiveFieldsBinocular1962" role="doc-biblioref">Hubel and Wiesel 1962</a>)</span>. These higher-level processes are what we have previously called ‘software’: they are not directly related to the physical brain, but they do process information heuristically to produce higher-level reasoning and conclusions. In the next section, we explore some of the higher-level processes responsible for visual perception.</p>
</section>
</section>
<section id="software" class="level2">
<h2 class="anchored" data-anchor-id="software">Software</h2>
<p>Many of the processes for visual perception run simultaneously; in absence of a strict temporal ordering, we will start with the more basic tasks of visual perception and proceed towards higher-level processes.</p>
<section id="attention-and-perception" class="level3">
<h3 class="anchored" data-anchor-id="attention-and-perception">Attention and Perception</h3>
<p>In many tasks, it is necessary to pay attention to many parallel input streams simultaneously; this is particularly true for complex tasks like driving a car. These tasks demand divided attention; the brain must process many different sources of information in parallel. By contrast, most image recognition tasks require selective attention, that is, focusing on specific objects and ignoring everything else. The brain accomplishes this attention through several mechanisms.</p>
<p>Selective attention is accomplished by focusing the fovea (the area with the highest visual acuity) on the object. For instance, if the object is a page of text, each word will pass through the fovea, producing a focused stream of visual input. This stream of input consists of saccades (jumps between points of focus) and pauses in which the visual information is relayed to the brain.</p>
<p>Selective attention is generally necessary for perception to occur, though there is some information that is encoded automatically. The <a href="http://www.theinvisiblegorilla.com/videos.html">“gorilla” film</a> experiment demonstrates that even when there is attention focused on a task, information extraneous to that task is not always encoded, that is, when participants focused on counting the number of passes between players in the basketball game, many did not notice the gorilla walking through the middle of the court. It is important to understand which parts of a visual stimulus are the focus of a given perceptual task, because most of the information encoded by the brain is a result of selective attention. Eye-tracking can be an important tool useful to understand these perceptual processes, but participants may also be able to self-report which parts of a stimulus contributed to their decision.</p>
<p>Within the brain, attention is important because it allows different regions of the brain which process color, shape, and position to integrate these perceptions into a multifaceted mental representation of the object <span class="citation" data-cites="goldsteinSensationPerception2022">(<a href="#ref-goldsteinSensationPerception2022" role="doc-biblioref">Goldstein and Cacciamani 2022</a>)</span>. This process, known as binding, is essential to coherently encode a scene into working memory. Feature integration theory <span class="citation" data-cites="treismanFeatureIntegrationTheoryAttention1980">(<a href="#ref-treismanFeatureIntegrationTheoryAttention1980" role="doc-biblioref">Treisman 1980</a>)</span> suggests that these separate streams of information are initially encoded in the preattentive stage of object perception; focusing on the object triggers the binding of these separate streams into a single coherent stream of information. Many single features, such as color, length, and texture are <em>preattentive</em>, because they can be pinpointed in an image without focused attention (and thus can be located faster), but specific combinations of color and shape require attention (because the features must be bound together) and are thus more difficult to search. Preattentive features are generally processed in parallel (that is, the entire scene is processed nearly simultaneously), while features requiring attention are processed serially.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-parallel-serial" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="01-Fundamentals_files/figure-html/fig-parallel-serial-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Figure&nbsp;4: Features detected serially or in parallel. In general, features detected in parallel are processed pre-attentively, while features detected serially require focused attention.</figcaption>
</figure>
</div>
</div>
</div>
<p>Examples of features processed serially and in parallel are shown in <a href="#fig-parallel-serial">Figure&nbsp;4</a> [<span class="citation" data-cites="helander1997handbook">Helander, Landauer, and Prabhu (<a href="#ref-helander1997handbook" role="doc-biblioref">1997</a>)</span>; Chapter 6].</p>
<p>Feature integration as a result of attention enables the brain to process a figure holistically and integrate all of the separate aspects of the object into a single perceptual experience. This processing is important for the most basic visual processes we take for granted, including object perception.</p>
</section>
<section id="object-perception" class="level3">
<h3 class="anchored" data-anchor-id="object-perception">Object Perception</h3>
<p>The most basic task of the visual system is to perceive objects in the world around us. This is an inherently difficult task, however, because the retina is a flat, two-dimensional surface responsible for conveying a three-dimensional visual scene. This dimensional reduction means that there are multiple three-dimensional stimuli that can produce the same visual image on the retina. This is known as the inverse projection problem - an infinite number of three-dimensional objects produce the same two-dimensional image. Less relevant to statistical graphics, but still complicating the object perception process, a single object can be viewed from a multitude of angles, in many different situations which may affect the retinal image (lighting, partial obstruction, etc). In addition, we recognize objects even when they are partially obscured or viewed from an angle we have not previously seen. These problems mean that the brain must utilize many different heuristics to increase the accuracy of the perceived world relative to an ambiguous stimulus.</p>
<p>The most commonly cited set of heuristics for object perception (and the set most relevant to statistical graphics) arise from the <em>Gestalt</em> school of psychology and are known as the <a href="https://en.wikipedia.org/wiki/Principles_of_grouping"><em>Principles of Grouping</em></a>. These principles relate to the idea ``the whole is greater than the sum of the parts’’, that is, that the components of a visual stimulus, when combined, create something that is more meaningful than the separate components considered individually. The Gestalt principles of grouping are as follows:</p>
<ul>
<li><strong>Pragnanz</strong> (the law of closure) Every stimulus pattern is seen so that the resulting structure is as simple as possible.</li>
<li><strong>Proximity</strong> Things that are close in space appear to be grouped.</li>
<li><strong>Similarity</strong> Similar items appear to be grouped together. The law of similarity is usually subordinate to the law of proximity.</li>
<li><strong>Good Continuation</strong> Points that can be connected to form straight lines or smooth curves seem to belong together, and lines seem to follow the smoothest path.</li>
<li><strong>Common Fate</strong> Things moving in the same direction are part of a single group.</li>
<li><strong>Familiarity</strong> Things are more likely to form groups if the groups are familiar.</li>
<li><strong>Common Region</strong> Things that are in the same region (container) appear to be grouped together</li>
<li><strong>Uniform Connectedness</strong> A connected region of objects is perceived as a single unit.</li>
<li><strong>Synchrony</strong> Events occurring at the same time will be perceived as belonging together.</li>
</ul>
<p>These principles are demonstrated in <a href="#fig-gestalt">Figure&nbsp;5</a>.</p>
<div id="fig-gestalt" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="../fig/gestalt.svg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: Gestalt principles of grouping</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="the-psychology-of-charts" class="level1">
<h1>The Psychology of Charts</h1>
<p>In this section, we’ll primarily focus on how the concepts introduced previously apply to statistical graphics. At first glance, the cognitive psychology introduced above may seem unrelated to graphics and perception; however, this could not be further from the truth. It is critical to understand and consider perception and cognition when creating graphics which facilitate easy comprehension of the underlying data in visual form.</p>
<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section"></h2>
</section>
</section>
<section id="strategies-for-readability" class="level1">
<h1>Strategies for Readability</h1>
<section id="center-primary-comparisons" class="level2">
<h2 class="anchored" data-anchor-id="center-primary-comparisons">Center Primary Comparisons</h2>
</section>
<section id="reduce-cognitive-load" class="level2">
<h2 class="anchored" data-anchor-id="reduce-cognitive-load">Reduce Cognitive Load</h2>
</section>
</section>
<section id="testing-multiple-versions-of-a-chart" class="level1">
<h1>Testing Multiple Versions of a Chart</h1>
<p>http://homepage.stat.uiowa.edu/~luke/classes/STAT4580-2024/notes.html#mostly-data-visualization</p>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-borlandRainbowColorMap2007" class="csl-entry" role="listitem">
Borland, D., and R. M. Taylor. 2007. <span>“Rainbow <span>Color Map</span> (<span>Still</span>) <span>Considered Harmful</span>.”</span> <em>IEEE Computer Graphics and Applications</em> 27 (2): 14–17. <a href="https://doi.org/10.1109/mcg.2007.323435">https://doi.org/10.1109/mcg.2007.323435</a>.
</div>
<div id="ref-goldsteinSensationPerception2022" class="csl-entry" role="listitem">
Goldstein, E. Bruce, and Laura Cacciamani. 2022. <em>Sensation and Perception</em>. Eleventh edition. <span>Australia</span>: <span>Cengage</span>.
</div>
<div id="ref-golebiowska2022a" class="csl-entry" role="listitem">
Golebiowska, I. M., and A. Coltekin. 2022. <span>“Rainbow Dash: <span>Intuitiveness</span>, Interpretability and Memorability of the Rainbow Color Scheme in Visualization.”</span> <em>IEEE Transactions on Visualization and Computer Graphics</em> 28, 07: 2722–33. <a href="https://doi.org/10.1109/TVCG.2020.3035823">https://doi.org/10.1109/TVCG.2020.3035823</a>.
</div>
<div id="ref-helander1997handbook" class="csl-entry" role="listitem">
Helander, M. G., T. K. Landauer, and P. V. Prabhu. 1997. <em>Handbook of Human-Computer Interaction</em>. Second. <span>North Holland</span>. <a href="http://gen.lib.rus.ec/book/index.php?md5=4941df4ad2ca3481b0dc4291667428b7">http://gen.lib.rus.ec/book/index.php?md5=4941df4ad2ca3481b0dc4291667428b7</a>.
</div>
<div id="ref-hubelReceptiveFieldsBinocular1962" class="csl-entry" role="listitem">
Hubel, D. H., and T. N. Wiesel. 1962. <span>“Receptive Fields, Binocular Interaction and Functional Architecture in the Cat’s Visual Cortex.”</span> <em>The Journal of Physiology</em> 160 (1): 106–54. <a href="https://doi.org/10.1113/jphysiol.1962.sp006837">https://doi.org/10.1113/jphysiol.1962.sp006837</a>.
</div>
<div id="ref-lightEndRainbowColor2004" class="csl-entry" role="listitem">
Light, Adam, and Patrick J Bartlein. 2004. <span>“The End of the Rainbow? <span>Color</span> Schemes for Improved Data Graphics.”</span> <em>Eos, Transactions American Geophysical Union</em> 85 (40): 385–91. <a href="https://doi.org/10.1029/2004EO400002">https://doi.org/10.1029/2004EO400002</a>.
</div>
<div id="ref-liuSomewhereRainbowEmpirical2018a" class="csl-entry" role="listitem">
Liu, Yang, and Jeffrey Heer. 2018. <span>“Somewhere <span>Over</span> the <span>Rainbow</span>: <span>An Empirical Assessment</span> of <span>Quantitative Colormaps</span>.”</span> In <em>Proceedings of the 2018 <span>CHI Conference</span> on <span>Human Factors</span> in <span>Computing Systems</span></em>, 1–12. <span>Montreal QC Canada</span>: <span>ACM</span>. <a href="https://doi.org/10.1145/3173574.3174172">https://doi.org/10.1145/3173574.3174172</a>.
</div>
<div id="ref-redaRainbowColormapsWhat2022" class="csl-entry" role="listitem">
Reda, Khairi. 2022. <span>“Rainbow <span>Colormaps</span>: <span>What</span> Are They Good and Bad For?”</span> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 1–15. <a href="https://doi.org/10.1109/TVCG.2022.3214771">https://doi.org/10.1109/TVCG.2022.3214771</a>.
</div>
<div id="ref-treismanFeatureIntegrationTheoryAttention1980" class="csl-entry" role="listitem">
Treisman, Anne M. 1980. <span>“A <span>Feature-Integration Theory</span> of <span>Attention</span>.”</span> <em>Cognitive Psychology</em> 12: 97–136. <a href="https://doi.org/10.1016/0010-0285(80)90005-5">https://doi.org/10.1016/0010-0285(80)90005-5</a>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>