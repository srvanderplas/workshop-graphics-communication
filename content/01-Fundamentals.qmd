---
title: "Fundamentals of Graphical Communication"
---

# A Quick Introduction to Perception and Cognition

In order to design graphics for the human perceptual system, we must understand, at a basic level, the makeup of the perceptual system. There are multiple levels of perception that must correctly function in order to perceive visual stimuli successfully, but a somewhat simplistic higher-level analogy would be that we must understand both the hardware and software of the human visual system to create effective graphics.

The "hardware", in this analogy, consists of the neurons that make up the eyes, optic nerve, and the brain itself. The higher-level functions (object recognition, working memory, etc.) comprise the "software" component. In addition, much like computer software, there are different programs running simultaneously; these programs may interact with each other, run sequentially, or run in parallel. Here, we provide an overview of the important components of the visual system that influence graphical perception. First, we discuss the grey-matter (hardware) components of the visual system, then we examine the higher-level cognitive heuristics (software) that order the raw input and construct our visual environment.

## Hardware

The physiology of perception is complex; what follows is a brief overview of the physiology of perception, focusing on the areas most important to the perception of statistical graphics. It is important to distinguish between the sensation (the retinal image) and the perception (the corresponding mental representation) of an object. This overview will entirely ignore the finer details of the organization of the brain: feature detector cells, specific processing units for certain types of visual stimuli, and most of the experiments and incidents that led to our current understanding of how the brain processes visual information. A more thorough presentation of these aspects of perception can be found in @goldsteinSensationPerception2022.

### The Eye

The eye is a complex apparatus, but for our purposes, the most important component of the eye is the retina, which contains the sensory cells responsible for transforming light waves into electrical information in the form of neural signals. These sensory cells are specialized neurons, known as rods and cones, which perceive light intensity (brightness) and wavelength (color), respectively. One section of the retina, known as the fovea, contains only cones; the rest of the retina contains a mixture of rods and cones. @fig-retina-diagram depicts the structure of the eye with a closeup of the retina.

![The human eye, with closeup of receptor cells in the retina.[[Image Source](https://commons.wikimedia.org/wiki/File:Figure_36_05_02.png) [License](https://creativecommons.org/licenses/by/4.0/deed.en) Authors: OpenStax Copyright Holders: Rice University Publishers: OpenStax OpenStax Biology]{.fig-citation}](https://upload.wikimedia.org/wikipedia/commons/9/9e/Figure_36_05_02.png){#fig-retina-diagram}

Another important region of the retina is the blindspot, the area where the optic nerve exits the eye to connect the retina to the brain. There are no rods or cones in this region of the retina, and any vision in the region of space that maps onto this point is a result of two mechanisms: binocular vision (the other eye fills in the missing information) and your brain "filling in" what it believes should be there.

![Absorption spectra of rods and short (blue), medium (green), and long (red) wave cones. [Image modified from [Pancrat's Wikimedia Commons work](https://commons.wikimedia.org/wiki/File:Spectre_absorption_des_cones.svg). [License](https://creativecommons.org/licenses/by-sa/3.0/deed.en).]{.fig-citation}](../fig/Absorption-Spectra-Retina.svg){#fig-color-range}

@fig-color-range shows the responsiveness of rods and each of the three types of cones to wavelengths of light in the visual spectrum. As a result of the response of cone cells to different wavelengths of light, humans with normal color vision can better distinguish colors in the yellow-green portion of the color spectrum compared to colors in the red or blue portions of the spectrum.

::: callout-tip
#### Implications for Color Schemes

Rainbow-style color schemes are seldom appropriate for conveying numerical values, because the correspondence between perceived information and the displayed information is not accurately maintained by the visual system [@golebiowska2022a; @liuSomewhereRainbowEmpirical2018a; @borlandRainbowColorMap2007; @lightEndRainbowColor2004]. Rainbow schemes may perform slightly better in situations where the goal is to emphasize distributions of values [@redaRainbowColormapsWhat2022], but this effect is small relative to the disadvantages of rainbow color schemes for accessibility and interpretability.

Moreover, if a viewer has any level of color vision impairment (colloquially, 'color blindness'), the viewer cannot perceive the full spectrum of colors. An estimated 5% of the population (10% of males, less than 1% of females) has some form of color vision impairment. Rainbow color schemes perform particularly poorly when color vision is impaired.
:::

### The Brain

Once light hits the retina and causes a signal in the receptor cells, the information travels along the optic nerve and into the brain. Multiple neighboring rods are connected to the same neuron, where each cone is connected to a single neuron. The combined wiring of rod cells is responsible for the [Hermann grid illusion](https://en.wikipedia.org/wiki/Grid_illusion#Theories) and the [Mach bands](https://en.wikipedia.org/wiki/Mach_bands) seen in @fig-inhibition-illusions. Both of these illusions are a product of lateral inhibition, which is a result of the wiring of rod cells in the retina. Essentially, neurons can only fire at a specific rate, so when neighboring cells are all stimulated simultaneously, the combined neuron cannot fire fast enough to pass on all of the signals, causing *inhibition*. The [specifics of this response](https://en.wikipedia.org/wiki/Grid_illusion#Theories) and its relationship with the wiring of the receptor cells are too complex for this summary.

::: {#fig-inhibition-illusions layout-ncol="2"}
![Hermann grid illusion [[Image Source](https://en.wikipedia.org/wiki/File:HermannGrid.svg). [License](https://creativecommons.org/publicdomain/zero/1.0/deed.en).]{.fig-citation}](https://upload.wikimedia.org/wikipedia/commons/b/be/HermannGrid.svg)

![Mach Bands [[Image Source](https://commons.wikimedia.org/wiki/File:Bandes_de_mach.PNG). [License](https://en.wikipedia.org/wiki/en:Free_Art_License).]{.fig-citation}](../fig/Mach-Bands.png)

Illusions which are thought to arise due to inhibition. In the Hermann grid illusion, dark blobs appear at the intersection of the white lines. In the Mach band illusion, the region where different shaded bands meet seems to have more contrast than the middle of the bands.
:::

Once neural impulses have left the retina through the optic nerve, they travel to the visual cortex by way of several specialized structures within the brain that process lower-level signals. Receptor cells in the visual cortex respond to specific angles, spatial locations, colors, and intensities, and arrays of these special 'feature detector cells' process the information into a form used by higher-level processes [@hubelReceptiveFieldsBinocular1962]. These higher-level processes are what we have previously called 'software': they are not directly related to the physical brain, but they do process information heuristically to produce higher-level reasoning and conclusions. In the next section, we explore some of the higher-level processes responsible for visual perception.

## Software

Many of the processes for visual perception run simultaneously; in absence of a strict temporal ordering, we will start with the more basic tasks of visual perception and proceed towards higher-level processes.

### Attention and Perception

In many tasks, it is necessary to pay attention to many parallel input streams simultaneously; this is particularly true for complex tasks like driving a car. These tasks demand divided attention; the brain must process many different sources of information in parallel. By contrast, most image recognition tasks require selective attention, that is, focusing on specific objects and ignoring everything else. The brain accomplishes this attention through several mechanisms.

Selective attention is accomplished by focusing the fovea (the area with the highest visual acuity) on the object. For instance, if the object is a page of text, each word will pass through the fovea, producing a focused stream of visual input. This stream of input consists of saccades (jumps between points of focus) and pauses in which the visual information is relayed to the brain.

Selective attention is generally necessary for perception to occur, though there is some information that is encoded automatically. The ["gorilla" film](http://www.theinvisiblegorilla.com/videos.html) experiment demonstrates that even when there is attention focused on a task, information extraneous to that task is not always encoded, that is, when participants focused on counting the number of passes between players in the basketball game, many did not notice the gorilla walking through the middle of the court. It is important to understand which parts of a visual stimulus are the focus of a given perceptual task, because most of the information encoded by the brain is a result of selective attention. Eye-tracking can be an important tool useful to understand these perceptual processes, but participants may also be able to self-report which parts of a stimulus contributed to their decision.

Within the brain, attention is important because it allows different regions of the brain which process color, shape, and position to integrate these perceptions into a multifaceted mental representation of the object [@goldsteinSensationPerception2022]. This process, known as binding, is essential to coherently encode a scene into working memory. Feature integration theory [@treismanFeatureIntegrationTheoryAttention1980] suggests that these separate streams of information are initially encoded in the preattentive stage of object perception; focusing on the object triggers the binding of these separate streams into a single coherent stream of information. Many single features, such as color, length, and texture are *preattentive*, because they can be pinpointed in an image without focused attention (and thus can be located faster), but specific combinations of color and shape require attention (because the features must be bound together) and are thus more difficult to search. Preattentive features are generally processed in parallel (that is, the entire scene is processed nearly simultaneously), while features requiring attention are processed serially.

```{r}
#| label: fig-parallel-serial
#| echo: false
#| message: false
#| warning: false
#| include: true
#| fig-cap: Features detected serially or in parallel. In general, features detected in parallel are processed pre-attentively, while features detected serially require focused attention.

suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
suppressMessages(library(dplyr))
suppressMessages(library(tidyr))
suppressMessages(library(purrr))

# Empty theme definition
new_theme_empty <- theme_bw(base_size=16)
new_theme_empty$line <- element_blank()
new_theme_empty$strip.text <- element_blank()
new_theme_empty$axis.text <- element_blank()
# new_theme_empty$plot.title <- element_blank()
new_theme_empty$axis.title <- element_blank()
# new_theme_empty$plot.margin <- structure(c(0, 0, -1, -1), unit = "lines", valid.unit = 3L, class = "unit")


parallel.points <- data.frame(
  color = c("red", "orange", "yellow", "green", "blue",
            "grey90", "grey70", "grey50", "grey30", "grey10"),
  shape = 16,
  x = rep(1:5, times=2),
  y = rep(c(5, 4), each=5)
)

gen.angles <- function(angle1=runif(1, 0, pi), angle2=runif(1, 0, pi/2), length=1, x=0, y=0){
  line1 <- data.frame(
    x = x,
    xend = x + length*cos(angle1),
    y = y,
    yend = y + length*sin(angle1)
    )
  line2 <- data.frame(
    x = line1$xend,
    xend = line1$xend + length*cos(angle2),
    y = line1$yend,
    yend = line1$yend + length*sin(angle2)
  )
  pacman <- rbind(line1, line2)
  pacman[,1:2] <- pacman[,1:2] - mean(range(unlist(pacman[,1:2]))) + x
  pacman[,3:4] <- pacman[,3:4] - mean(range(unlist(pacman[,3:4]))) + y
  pacman
}

gen.slopes <- function(angle=runif(1, 0, pi), length=.5, x=0, y=0){
  data.frame(
    x = x - length*cos(angle)/2,
    xend = x + length*cos(angle)/2,
    y = y - length*sin(angle)/2,
    yend = y + length*sin(angle)/2
    )
}

angle.set <- sample(seq(0, pi/2, length.out=5), 5)
ystart <- 1 - sample(seq(.25, .625, length.out=5), 5)
yend <- ystart + sort(sample(seq(.2, 1, length.out=5), 5))
parallel.segments <- dplyr::bind_rows(
  do.call("rbind", lapply(1:5, function(i) gen.slopes(x=i, angle=angle.set[i], length=.5, y=2))), # slope
  do.call("rbind", lapply(1:5, function(i) gen.angles(x=i, length=.5, y=3))), # angles
  data.frame( x = 1:5, xend = 1:5, y=ystart , yend=yend) # length
)

parallel <-
  ggplot() + new_theme_empty +
  geom_point(aes(x=x, y=y, color=color, shape=shape), data=parallel.points, size=8) + scale_shape_identity() + scale_color_identity() +
  geom_segment(aes(x=x, xend=xend, y=y, yend=yend), data=parallel.segments) +
  geom_text(aes(x=-0.5, y=1:5, label=c("Length", "Slope", "Angle", "Value", "Color")), hjust=0, vjust=.5) +
  ggtitle("Parallel Detection") 

serial.points <- data.frame(
    x = c(rep(1:5, times=2), 4.5, 1.75),
    y = c(rep(c(5, 4), each=5), 2, 2.1),
    shape = c(15, 16, 17, 8, 3, rep(16, 5), 1, 5),
    size = c(rep(8, 5), c(4, 6, 8, 10, 12), 10, 6)
  )

serial.lines <- data.frame(
    x = jitter(
      c(cos(c(seq(0, pi, length.out=5), rev(seq(pi, 0, length.out=5))))/2+1.5,
        seq(2.5, 3.25, length.out=4), 3.5, 3.5, rev(seq(2.5, 3.25, length.out=4)),
        seq(4, 5, length.out=3), rev(seq(4, 5, length.out=4)), seq(4, 5, length.out=3))
      ),
    y = c(sin(seq(pi/2, 3*pi/2, length.out=10))^2/+3,
          sin(seq(pi/2, 3*pi/2, length.out=10))/2+3,
          rnorm(10, 3, .25)),
    group = rep(1:3, each=10)
  )

fix_lines <- function(df){
  xspline <- data.frame(spline(x=1:nrow(df), y=df$x, n=100))
  yspline <- data.frame(spline(x=1:nrow(df), y=df$y, n=100))

  tmp <- data.frame(x=xspline$y, y=yspline$y)
  tmp$y <- (tmp$y-mean(tmp$y))/(max(tmp$y) - min(tmp$y))/1.5 + 3
  return(tmp)
}

serial.lines2 <- serial.lines %>%
  tidyr::nest(data = -group) %>%
  mutate(data2 = map(data, fix_lines)) %>%
  tidyr::unnest(data2)

serial.rects <- data.frame(
    xmin = c(1.375, 2.1),
    xmax = c(5, 4),
    ymin = c(1.6, 1.8),
    ymax = c(2.4, 2.2)
  )

serial.segments <- data.frame(
  x = c(seq(1.25, 2, length.out=4), seq(2.5, 3.25, length.out=4), rep(4.25, 4)),
  xend = c(seq(1.25, 2, length.out=4), seq(3, 3.75, length.out=4), rep(5, 4)),
  y = c(rep(.625, 4), rev(seq(.5, .9, length.out=4)), seq(.75, 1.25, length.out=4)),
  yend = c(rep(1.375, 4), rev(seq(1, 1.4, length.out=4)), seq(.75, 1.25, length.out=4))
)


serial <- ggplot() + new_theme_empty +
  geom_point(aes(x=x, y=y, size=size, shape=shape), data=serial.points) +
  geom_path(aes(x=x, y=y, group=group), data=serial.lines2, color="black") +
  geom_rect(aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax), data=serial.rects, fill="transparent", color="black") +
  geom_segment(aes(x=x, xend=xend, y=y, yend=yend), data=serial.segments) +
  scale_shape_identity() +
  scale_size_identity() +
  geom_text(aes(x=-0.5, y=rev(1:5), label=c("Shape", "Area", "Curvature", "Containment", "Orientation")), hjust=0, vjust=.5) +
  ggtitle("Serial Detection") 

grid.arrange(parallel, serial, ncol=2)

```

Examples of features processed serially and in parallel are shown in @fig-parallel-serial [@helander1997handbook; Chapter 6].

Feature integration as a result of attention enables the brain to process a figure holistically and integrate all of the separate aspects of the object into a single perceptual experience. This processing is important for the most basic visual processes we take for granted, including object perception.

### Object Perception

The most basic task of the visual system is to perceive objects in the world around us. This is an inherently difficult task, however, because the retina is a flat, two-dimensional surface responsible for conveying a three-dimensional visual scene. This dimensional reduction means that there are multiple three-dimensional stimuli that can produce the same visual image on the retina. This is known as the inverse projection problem - an infinite number of three-dimensional objects produce the same two-dimensional image. Less relevant to statistical graphics, but still complicating the object perception process, a single object can be viewed from a multitude of angles, in many different situations which may affect the retinal image (lighting, partial obstruction, etc). In addition, we recognize objects even when they are partially obscured or viewed from an angle we have not previously seen. These problems mean that the brain must utilize many different heuristics to increase the accuracy of the perceived world relative to an ambiguous stimulus.

The most commonly cited set of heuristics for object perception (and the set most relevant to statistical graphics) arise from the *Gestalt* school of psychology and are known as the [*Principles of Grouping*](https://en.wikipedia.org/wiki/Principles_of_grouping). These principles relate to the idea \`\`the whole is greater than the sum of the parts'', that is, that the components of a visual stimulus, when combined, create something that is more meaningful than the separate components considered individually. The Gestalt principles of grouping are as follows:

-   **Pragnanz** (the law of closure) Every stimulus pattern is seen so that the resulting structure is as simple as possible.
-   **Proximity** Things that are close in space appear to be grouped.
-   **Similarity** Similar items appear to be grouped together. The law of similarity is usually subordinate to the law of proximity.
-   **Good Continuation** Points that can be connected to form straight lines or smooth curves seem to belong together, and lines seem to follow the smoothest path.
-   **Common Fate** Things moving in the same direction are part of a single group.
-   **Familiarity** Things are more likely to form groups if the groups are familiar.
-   **Common Region** Things that are in the same region (container) appear to be grouped together
-   **Uniform Connectedness** A connected region of objects is perceived as a single unit.
-   **Synchrony** Events occurring at the same time will be perceived as belonging together.

These principles are demonstrated in @fig-gestalt.

![Gestalt principles of grouping](../fig/gestalt.svg){#fig-gestalt}

# The Psychology of Charts

In this section, we'll  primarily focus on how the concepts introduced previously apply to statistical graphics. 
At first glance, the cognitive psychology introduced above may seem unrelated to graphics and perception; however, this could not be further from the truth. 
It is critical to understand and consider perception and cognition when creating graphics which facilitate easy comprehension of the underlying data in visual form. 

## 

# Strategies for Readability

## Center Primary Comparisons

## Reduce Cognitive Load

# Testing Multiple Versions of a Chart

http://homepage.stat.uiowa.edu/\~luke/classes/STAT4580-2024/notes.html#mostly-data-visualization
