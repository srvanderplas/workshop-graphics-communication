---
title: "Accessibility"
subtitle: "More than just Alt-text"
format: 
  revealjs:
    theme: [default, inverse.scss]
include-before-body:
  text: |
    <!-- olli -->
    <script src="https://cdn.jsdelivr.net/npm/olli@2"></script>
    <script src="https://cdn.jsdelivr.net/npm/olli-adapters@2"></script>
    <!-- scramble-script -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.7.1/jquery.min.js"></script>
    <script src="scramble.js"></script>
---

# Data Vis:    
[Minimum Human Specs]{.emph .cerulean style="font-size:2em;float:right;"}

## Perception requires {auto-animate=true}

::: {.columns}

::: {.column}
::: {.fragment style="min-height:5em"}
[Visual acuity]{data-id="acuity" style="vertical-align:middle;"} ![](../fig/magnifying-glass-text.png){style="width:30%;vertical-align:middle;"}
:::

::: {.fragment style="vertical-align:bottom;min-height:5em;"}
[Color Vision]{data-id="color" style="vertical-align:middle;text-align:left;"}    
![](../fig/Absorption-Spectra-Retina.svg){style="width:100%;vertical-align:middle;text-align:left;"} 
:::
:::

::: {.column}
::: {.fragment style="text-align:right;min-height:5em"}
[Feature Integration]{data-id="attn"}    
(& focused attention!)
:::

::: {.fragment style="vertical-align:bottom;text-align:center;min-height:5em;margin-top:1em;"}
[Grouping & Sense-making]{data-id="grouping"  style="vertical-align:middle;text-align:right;"}    
![](../fig/gestalt.svg){style="width:100%;vertical-align:middle;text-align:right;"}
:::
:::

:::



## Perception requires {auto-animate=true}

::: {.columns}

::: {.column}
::: {style="display:block;width=100%;padding-bottom:3em"}
[Far-sightedness]{.emph .darkgrey style="float:left"}     
[Vision]{data-id="acuity" style="vertical-align:middle;float:left;"}[Blind/Low Vision]{.emph .blue style="float:left;padding-left:2%;"}     
[Macular degeneration]{.emph .red style="float:left"} 
:::

::: {style="vertical-align:bottom;width=100%"} 
[Protanopia]{.emph .red style="padding-left:10%;float:left;"}    
[Color Vision]{data-id="color"  style="float:left;"} [Deuteranopia]{.emph .green style="float:left;padding-left:10%;"}    
[Tritanopia]{.emph .blue style="padding-left:10%;"}
:::
:::

::: {.column}
::: {style="text-align:right;padding-bottom:3em"}
[ADHD]{.emph .purple} [Feature Integration]{data-id="attn"}    
(& focused attention!)    
[Sensory Processing Disorder]{.emph .orange}
:::

::: {style="vertical-align:bottom;text-align:right;"}
[&nbsp;]{style="float:left;"}    
[Grouping & Sense-making]{data-id="grouping"  style="vertical-align:middle;float:right;"}    
[Schizophrenia]{.emph .cerulean style="vertical-align:middle;float:right;"}
:::
:::

:::


::: notes
When you step back and think about everything that can go wrong with the process of perceiving, understanding, and interacting with a data visualization, it's a bit of a miracle that these things are useful!

For each of these steps, I've listed conditions that may impact the underlying cognitive processes - this is not a clinical definition, because every person and their symptoms are different, but a way to make you aware of the challenges your audience may face.

Some of these issues are obviously harder to work around than others: if you are entirely blind, for instance, the information presented visually isn't going to have a chance to make it to working memory; if you're color vision impaired, you may have to expend more effort to figure out what a chart is saying, and you may get things wrong.

If you have problems with grouping and sense-making, you may be able to get some information off of the axes and the chart title, but not be able to make full use of the data represented.
:::

## Understanding Requires {auto-animate=true}


::: {.fragment fragment-index=0"}
[**Reading comprehension**. [Most charts have some text: title, axis labels, legends, and annotations. Any perceptual issues that affect reading affect data communication.]{#scramble .small}]{data-id="reading"}
<script type="text/javascript" src="scramble.js"></script>
:::

::: {style="display:inline-block;padding-bottom:2em;width:100%"}
::: {.fragment fragment-index=1 style="float:left;text-align:left;width:50%;vertical-align:middle;"}
[**Working Memory**]{data-id="wm" style="vertical-align:middle;"}  ![](../fig/Working Memory.png){style="vertical-align: middle;width:30%;padding-left:5px;"}
:::

::: {.fragment fragment-index=2 style="float:right;text-align:right;width:50%;vertical-align:middle;"}
[![](https://upload.wikimedia.org/wikipedia/commons/9/98/Mental_rotation_task_%28diagram%29_%28cropped%29.jpg){style="vertical-align:middle;width:30%;padding-right:5px;"} [**Spatial reasoning**]{data-id="spatial" style="vertical-align:middle;"}]{style="text-align:right;"}
:::
:::

::: {style="display:inline-block;width:100%"}

::: {.fragment fragment-index=3 style="float:right;text-align:right;vertical-align:top;width:50%;"}
[**Numeracy**]{data-id="num"}
:::

::: {.fragment fragment-index=4 style="float:left;vertical-align:top;width:50%;"}
[**Information from LTM**]{data-id="ltm"}
:::

:::


## Understanding Requires {auto-animate=true}

::: {style="display:block;width:100%;padding-bottom:2em;"}
[**Reading comprehension**.]{data-id="reading"}    
[Language Learner]{.emph .green style="float:left;padding-right:10%;"} [Low Literacy]{.emph .red style="float:left;padding-right:10%;padding-left:10%;"} [Dyslexia]{.emph .cerulean style="float:right;"} 
:::


::: {style="display:inline-block;width:100%;padding-bottom:2em;"}
::: {style="float:left;text-align:left;width:50%;vertical-align:bottom;"}
[Long COVID]{.emph .orange style="float:left;"}      
[**Working Memory**]{data-id="wm"} [ADHD]{.emph .purple style="float:right;padding-right:10%;"}     
[Dementia]{.emph .darkgrey style="float:left;"} [Multitasking]{.emph .blue style="float:right;padding-right:20%;"}
:::

::: {style="float:right;text-align:center;width:50%;"}
[Dyslexia]{.emph .cerulean style="float:right;"}    
[ADHD]{.emph .purple style="float:left;padding-left:10%;"} [**Spatial reasoning**]{data-id="spatial" style="float:right;vertical-align:middle;"}    
:::
:::

::: {style="display:inline-block;width:100%;"}
::: {style="float:left;text-align:left;width:60%;vertical-align:bottom;"}
[Dementia]{.emph .darkgrey style="float:left"}     
[**Information from LTM**]{data-id="ltm"}    
[New parent]{.emph .red style="float:left;padding-left:30%;"}
:::

::: {style="float:right;text-align:center;vertical-align:bottom;width:40%;"}
[Math Phobia]{.emph .orange style="float:right;"}    
[**Numeracy**]{data-id="num" style="float:right;"}      
[Dyscalculia]{.emph .green style="float:right;"}
:::
:::


::: notes
The biggest point I want to emphasize here is that challenges related to graphical perception are not necessarily traditional semi-permanent or permanent disabilities - a new parent might have transient, sleep-deprivation related memory loss that has just as much impact as dementia might have on an older adult. 

You'll notice that some conditions show up more often - ADHD impacts attention, but also working memory; Dementia obviously impacts many different aspects of perception. Similarly, the steps you might take to design for a population that includes nonnative speakers or language learners may be similar to the steps you take to support people with low literacy or dyslexia. 

The last thing I have to say in this introduction is that there are no silver bullets or magic fixes - making accessible data visualizations is hard, and you have to know your audience and be willing to test things out - on yourself first, but then on populations you hope to target design changes towards.
:::


# [Adapting Existing Graphics]{.slightly-small}

[Let's go from easy to hard...]{.emph .cerulean style="font-size:2em"}

## Color Vision Impairment

- Avoid red/green combinations (rainbows, stoplights)
- Use palettes designed to be more accessible to people with impaired color vision [\[Good: [Okabe-Ito](https://jfly.uni-koeln.de/color/), [Tol](https://thenode.biologists.com/data-visualization-with-flying-colors/research/). Avoid ColorBrewer.\]]{.small}

- Dual encode colors with other attributes (shape, linetype)

- Design your chart to be black-and-white printer compatible

## Blind and Low-Vision Users

- Can screen reader users 
    - navigate the document/site using a keyboard?
    - 'see' that a chart exists? 
    - access a basic summary of the chart?
    - examine the data or summary stats directly?

- Accessibility Audit tools:
    - [Chartability](https://chartability.fizz.studio/) accessibility audit (top to bottom)
    - [https://www.accessibilitychecker.org/](https://www.accessibilitychecker.org/) (W3C specs)


## W3C (A) Guidelines

- Color is not the only visual indicator for information    
  [Dual encoding by another name]{.emph .purple}
  
- Audio: if plays automatically, controls are provided:
    - Pause/Stop
    - Volume (independent of system volume)


## W3C (AA) Guidelines

- Contrast: ratio of 4.5:1, or 3:1 for large text
- Text settings can change without loss of function:
  - 200% magnification
  - 1.5x line spacing, 2x paragraph spacing
- Use text, rather than images of text
- Responsive content: no 2d scrolling required
- User Interface and graphical objects have 3:1 contrast
- Hover/focus content is persistent but can be dismissed


## W3C (AAA) Guidelines

- Enhanced Contrast (7:1) for text and images of text
  - 4.5:1 for large text
  
- Low/No background audio

- Text blocks:
  - User-selectable foreground/background color
  - No more than 80 characters wide
  - 1.5x line spacing within paragraphs
  - 1.5 x (line spacing) between paragraphs
  - 200% text zoom does not require horizontal scrolling
  
## Testing Contrast Values

```{r}
#| echo: false
library(colorspace)
library(tibble)
library(gt)
library(dplyr)
library(tidyr)
df <- tibble(
  is_col = rep(c(T, F), c(7, 3)),
  colors = c("#d00000", "#f58a1f", "#ffd74f", "#1b8500", 
             "#249ab5", "#005d84", "#a5228d", 
             "#ffffff", "#777879", "black"),
  white = contrast_ratio(col = colors),
  black = contrast_ratio(col = colors, col2 = "black")) |>
  pivot_longer(c(white, black), names_to = "background", values_to = "contrast") |>
  mutate(contrast_md = sprintf("[%02.02f]{style='color:%s;background-color:%s'}", contrast, colors, background)) 
  
df1_format <- df |> 
  filter(is_col) |> 
  select(-c(contrast, is_col)) |> 
  pivot_wider(names_from = colors, values_from = contrast_md)
  
df2_format <- df |> 
  filter(!is_col) |> 
  select(-c(contrast, is_col)) |> 
  pivot_wider(names_from = colors, values_from = contrast_md)

res1 <- df1_format[,-1] 
names(res1) <- NULL
res1 <- as.matrix(res1)

res2 <- df2_format[,-1] 
names(res2) <- NULL
res2 <- as.matrix(res2)

knitr::kable(res1, row.names = F, format = "pipe")
knitr::kable(res2, row.names = F, format = "pipe")

```

- `colorspace` R package will calculate this for you
- https://cliambrown.com/contrast/